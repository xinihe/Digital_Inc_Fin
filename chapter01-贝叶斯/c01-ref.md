

Gamma Link: https://gamma.app/docs/Bayer-7cpw0m4nar8fbgj?mode=doc


# è´å¶æ–¯æ¨æ–­

>è´å¶æ–¯æ¨æ–­åœ¨æ•°å­—æ™®æƒ é‡‘èä¸­é€šè¿‡åŠ¨æ€å­¦ä¹ æœºåˆ¶æŒç»­ä¼˜åŒ–æ¨¡å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å°‘é‡æ•°æ®å¹¶ç»“åˆå…ˆéªŒçŸ¥è¯†ï¼ˆå¦‚è¡Œä¸šç»éªŒæˆ–åŒºåŸŸç‰¹å¾ï¼‰é™ä½æœåŠ¡é—¨æ§›ï¼ŒåŒæ—¶ä»¥æ¦‚ç‡é‡åŒ–é£é™©ï¼ˆå¦‚è¿çº¦å¯èƒ½æ€§ï¼‰å¢å¼ºå†³ç­–é€æ˜åº¦ï¼Œå…¶çµæ´»æ€§å¯å¤„ç†ç»æµæ³¢åŠ¨ã€åœ°åŸŸå·®å¼‚ç­‰å¤æ‚åœºæ™¯å˜é‡ï¼Œå¹¶é€šè¿‡æ¸…æ™°å±•ç¤ºå…³é”®å½±å“å› ç´ ï¼ˆå¦‚æ”¶å…¥ç¨³å®šæ€§ã€ä¿¡ç”¨å†å²ï¼‰æå‡æ¨¡å‹å¯è§£é‡Šæ€§ï¼Œå°¤å…¶é€‚ç”¨äºæ•°æ®åŒ®ä¹çš„å†œæ‘æˆ–å°å¾®ä¼ä¸šä¿¡è´·åœºæ™¯ï¼Œåœ¨ä¿éšœé‡‘èå®‰å…¨çš„åŒæ—¶å®ç°ç²¾å‡†æœåŠ¡è¦†ç›–ã€‚




> [!example] ä¸¾ä¸ªä¾‹å­ 
> å‡è®¾æŸé“¶è¡Œéœ€è¯„ä¼°ä¸€ä½ç§æ¤æ°´ç¨»çš„å†œæ°‘ä¿¡ç”¨é£é™©ï¼Œåˆå§‹æ ¹æ®å½“åœ°å†œä¸šè´·æ¬¾ç»éªŒï¼ˆå…ˆéªŒçŸ¥è¯†ï¼‰è®¾å®šå…¶è¿çº¦æ¦‚ç‡ä¸º 15%ã€‚è¿›ä¸€æ­¥æ”¶é›†æ•°æ®ï¼šè¯¥å†œæ°‘æ‹¥æœ‰ 5 äº©å†œç”°ã€ç§æ¤é«˜æŠ—æ—±å“ç§ä¸”è¿‡å»ä¸¤å¹´æŒ‰æ—¶è¿˜æ¬¾ã€‚è´å¶æ–¯æ¨¡å‹å°†è¿™äº›æ–°ä¿¡æ¯ä¸å…ˆéªŒç»“åˆï¼Œé€šè¿‡æ¦‚ç‡è®¡ç®—åŠ¨æ€è°ƒæ•´è¿çº¦æ¦‚ç‡è‡³ 8%ï¼Œå¹¶é‡åŒ–å¤©æ°”å¹²æ—±ï¼ˆå½±å“æ”¶æˆï¼‰ã€ç²®é£Ÿä»·æ ¼æ³¢åŠ¨ç­‰ä¸ç¡®å®šå› ç´ å¯¹ç»“æœçš„å…·ä½“å½±å“æƒé‡ã€‚é“¶è¡Œå¯æ®æ­¤çµæ´»è®¾å®šè´·æ¬¾é¢åº¦æˆ–åˆ©ç‡ï¼Œæ—¢è§£å†³å†œæ‘åœ°åŒºå†å²æ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œåˆä»¥é€æ˜çš„æ¦‚ç‡è¯„ä¼°ï¼ˆå¦‚ â€œå½“å‰è¿çº¦é£é™© 8%â€ï¼‰å’Œå…³é”®å› ç´ è§£é‡Šï¼ˆå¦‚ â€œå¹²æ—±å¯¼è‡´é£é™©å¢åŠ  3%â€ï¼‰æå‡å†³ç­–å¯ä¿¡åº¦ï¼Œå®ç°ç²¾å‡†é£é™©ç®¡æ§ã€‚

| Name    | Age | City      |
| ------- | --- | --------- |
| Alice   | 24  | New York  |
| Bob     | 30  | San Diego |
| Charlie | 28  | Chicago   |

| Task         | Status    | Priority |     |
| ------------ | --------- | -------- | --- |
| Write report | âœ… Done    | ğŸ”´ High  |     |
| Review notes | â³ In Prog | ğŸŸ¡ Med   |     |
| Plan agenda  | âŒ› Pending | ğŸ”µ Low   |     |
|              |           |          |     |

| Name    | Role       | Status   |
|---------|------------|----------|
| Alice   | Researcher | âœ… Active |
| Bob     | Reviewer   | âŒ Left   |
| Carol   | Analyst    | â³ Pending|



```python
from math import log2
from matplotlib import pyplot

# calculate entropy

def entropy(events, ets=1e-15):
 return -sum([p * log2(p + ets) for p in events])

# define probabilities

probs = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]

# create probability distribution

dists = [[p, 1.0 - p] for p in probs]

# calculate entropy for each distribution

ents = [entropy(d) for d in dists]

# plot probability distribution vs entropy

pyplot.plot(probs, ents, marker='.')
pyplot.title('Probability Distribution vs Entropy')
pyplot.xticks(probs, [str(d) for d in dists])
pyplot.xlabel('Probability Distribution')
pyplot.ylabel('Entropy (bits)')
pyplot.show()
```



<figure>
Â  <img src="assets/fig0-1.png" alt="Entropy Plot" width="600">
Â  <figcaption>Figure 1: Entropy vs Probability Distribution</figcaption>
</figure>

## ğŸ§ **ä»€ä¹ˆæ˜¯è´å¶æ–¯æ¨æ–­** 



## ğŸ“… ç”Ÿæ´»ä¸­çš„è´å¶æ–¯




## å…³äºè´å¶æ–¯çš„å‡ ä¸ªé‡è¦éƒ¨åˆ†


### ä¼¼ç„¶å‡½æ•°


### å…ˆéªŒæ¦‚ç‡

### åéªŒæ¦‚ç‡